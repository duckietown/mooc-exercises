{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d74be3-94ef-4c6b-bb39-11f266220c03",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\">\n",
    "  <img src=\"../images/dtlogo.png\" alt=\"Logo\" width=\"200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e59e9-1672-4fd9-97ac-6845a69db358",
   "metadata": {},
   "source": [
    "# ðŸ’» 02 - Homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8af5f-ad20-4e22-9ee3-685774c14d80",
   "metadata": {},
   "source": [
    "The pinhole camera model provides a many-to-one mapping between points in the scene and their corresponding projection onto the image plane. With knowledge of the intrinsic and extrinsic parameters that specify the camera matrix, we can relate points in the image to their corresponding rays in the scene. However, we don't know where along this ray the corresponding scene point lies.\n",
    "\n",
    "One way of resolving some of this ambiguity is to use prior knowledge of the environment geometry as a means of adding further structure to the projetion model. In the case of Duckietown, we will use the fact that the environment is planar. In other settings, including self-driving vehicles, while the world may not be globally planar, we can treat it as locally planar around the robot (e.g., imagine the tangent plane on the curved surface that the robot is driving on). We can then exploit this planarity to constrain the projection model.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"text-align:center;\">\n",
    "  <img src=\"../images/homography/image-ground-projection.png\", width=\"400px\" />\n",
    "  <p>A homography provides an invertible transformation between the homogeneous coordinates of points in two planes.</p>\n",
    "  </div>\n",
    "</figure>\n",
    "\n",
    "Consider the scenario above in which the world is planar and consists of a collection of points $\\mathbf{X}_i, \\; i \\in \\{1,2,\\ldots,n\\}$, expressed in homogeneous coordinates. These points project to points $\\mathbf{x}_i$ in an image of the scene. We can relate each point-pair according to the camera projection matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i = \n",
    "\\begin{bmatrix}\n",
    "f_x & s & p_x\\\\\n",
    "0 & f_y & p_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{R} \\; \\vert \\; \\mathbf{t}\n",
    "\\end{bmatrix} \\mathbf{X}_i\n",
    "$$\n",
    "\n",
    "where $\\mathbf{R}$ and $\\mathbf{t}$ are the rotation matrix and translation vector, respectively, that define the transformation from the world frame to the camera frame. Since we are free to define the world frame as we see fit, let's define it such that the world plane lies in the $x-y$ plane with the $z$-axis orthogonal and pointing up. We can then write the projection operation as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{x}_i &= \n",
    "\\begin{bmatrix}\n",
    "f_x & s & p_x\\\\\n",
    "0 & f_y & p_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & R_{13} & t_x\\\\\n",
    "R_{21} & R_{22} & R_{23} & t_y\\\\\n",
    "R_{31} & R_{32} & R_{33} & t_z\\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "Z_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "f_x & s & p_x\\\\\n",
    "0 & f_y & p_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & R_{13} & t_x\\\\\n",
    "R_{21} & R_{22} & R_{23} & t_y\\\\\n",
    "R_{31} & R_{32} & R_{33} & t_z\\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix} \\quad \\textrm{since } Z_i = 0\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "f_x & s & p_x\\\\\n",
    "0 & f_y & p_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & t_x\\\\\n",
    "R_{21} & R_{22} & t_y\\\\\n",
    "R_{31} & R_{32} & t_z\\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "H_{11} & H_{12} & H_{13}\\\\\n",
    "H_{21} & H_{22} & H_{23}\\\\\n",
    "H_{31} & H_{32} & H_{33}\\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The matrix $H$ defines a projective transformation and is referred to as a *homography*. The matrix is full-rank and defines an invertible mapping between points in the world and their corresponding projection in the image, i.e.,\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\mathbf{x}_i &= H \n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\\\\\n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix} &= H^{-1} \\mathbf{x}_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "While the homography matrix has 9 elements, we can multiply $H$ by any non-zero constant without affecting the projection. To see this, supose that we have the following transformation involving non-homogeneous image coordinates $[x_i \\; y_i]^\\top$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_i\\\\\n",
    "y_i\\\\\n",
    "1\n",
    "\\end{bmatrix} = H\n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Multiplying $H$ by a non-zero constant $\\lambda$ yields\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\lambda x_i\\\\\n",
    "\\lambda y_i\\\\\n",
    "\\lambda\n",
    "\\end{bmatrix} = (\\lambda H)\n",
    "\\begin{bmatrix}\n",
    "X_i\\\\\n",
    "Y_i\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Since these are homogeneous coordinates, the result is the same non-homogeneous coordinates $[x_i \\; y_i]^\\top$ for the projected point. Thus, while the homography matrix consists of 9 values, it only has 8 degrees-of-freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e09697-5722-47cd-879f-448abb83c6d3",
   "metadata": {},
   "source": [
    "### Example: Exploring a Homography\n",
    "\n",
    "Homographies define a projection from one plane to another. Above, we described this in the context of a projection $H$ from points that lie on a plane in the world to the image plane for a particular camera pose. The homography provides a one-to-one mapping of points in the world plane to their corresponding projection in the image. If we were to move the camera to a different pose, there would similarly be a different homography $\\bar{H}$ relating the image to the ground plane.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"text-align:center;\">\n",
    "  <img src=\"../images/homography/image-ground-image-projection.png\", width=\"600px\" />\n",
    "  <p>A visualization of a simple pinhole camera.</p>\n",
    "  </div>\n",
    "</figure>\n",
    "\n",
    "We can compose these homographies to get a homography that relates the homogeneous coordinates of points in one image to their corresponding coordinates in the second image.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{x}_i &= H \\mathbf{X}_i\\\\\n",
    "&= H\\left(\\bar{H}^{-1}\\mathbf{x}^\\prime_i\\right)\\\\\n",
    "&= \\left(H\\bar{H}^{-1}\\right)\\mathbf{x}^\\prime_i\\\\\n",
    "&= \\check{H}\\mathbf{x}^\\prime_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\check{H} = H\\bar{H}^{-1}$ is the homography between the two images that is induced by the ground plane.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"text-align:center;\">\n",
    "  <img src=\"../images/homography/bt.000.png\", width=400px>\n",
    "  <img src=\"../images/homography/bt.002.png\", width=400px>\n",
    "  <p>Two images of a hallway on the Oxford campus taken from different viewpoints. The planar ground induces a homography $\\check{H}$ between the two images.</p>\n",
    "  </div>\n",
    "</figure>\n",
    "\n",
    "In this example, you will explore the use of a homography to relate images of the same scene taken from different poses. While the scene is not planar, there are planes in the scene that can be used to induce a homography between the two views. In the example below, the floor (ground) plane was used to estimate the homography. In this exercise, you will explore the validity of this homography and see whether it provides a valid transformation between points that don't lie on the ground.\n",
    "\n",
    "Do you think that the transformation will be valid for points that lie on the walls? Why/why not? (Specifically, pay close attention to the right wall, closer to the camera.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e77595-ef15-4a2e-a65d-56d3e047e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to import relevant modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib tk\n",
    "%pylab tk\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8245c-1f6c-4347-b4cd-d7908324cc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Running this cell will bring up a figure displaying the two above images of the scene. When you click a point in the left image,\n",
    "#.      the projected point in the right image will be rendered according to the homography induced by the ground plane.\n",
    "#.      Compare the accuracy of the correspondences for points that lie on the ground plane to points elsewhere in the environment.\n",
    "imgl = cv2.imread('../images/homography/bt.000.png', 0)\n",
    "imgr = cv2.imread('../images/homography/bt.002.png', 0)\n",
    "\n",
    "H = np.array([[0.907503833504229, -0.116496578881938, 30.8471918181923],[0.00308072860216055, 0.828815989469247, 16.0448537015201],[-1.74015013507422e-05, -0.000441721032603193, 1]])\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(imgl,cmap = 'gray')\n",
    "ax1.set_title('Source Image');\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(imgr,cmap = 'gray')\n",
    "ax2.set_title('Target Image');\n",
    "\n",
    "def onclick(event):\n",
    "    # Apply the homography\n",
    "    x = np.array([[event.xdata, event.ydata, 1]]).transpose()\n",
    "    xprime = H.dot(x)\n",
    "    xprime = xprime/xprime[2]\n",
    "    \n",
    "    # Visualize the selected and projected points\n",
    "    ax1.plot(x[0], x[1], 'rx')\n",
    "    ax2.plot(xprime[0], xprime[1], 'rx')\n",
    "    plt.show()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48d6d2-8d99-4349-8b23-5f2b62c6275e",
   "metadata": {},
   "source": [
    "You can now move to the [camera calibration tutorial](../03-Camera-Calibration/camera_calibration.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
