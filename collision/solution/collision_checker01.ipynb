{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision checking\n",
    "\n",
    "As part of this exercise, you will write your very own collision checker. While this checker will only function in-simulation, it should give you a good idea of the complexity associated with detecting collisions in the real world.\n",
    "\n",
    "We have defined a few data structures that you will use in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures and protocol\n",
    "\n",
    "The data structures are defined in the [`dt-protocols-daffy`](https://github.com/duckietown/dt-protocols) package.\n",
    "\n",
    "In particular, you can look in [`collision_protocol.py`][file] the data structures to use.\n",
    "\n",
    "We **strongly** suggest opening the [`collision_protocol.py`][file] link/file in a separate window, and cross-referencing the information given here with the code definition given in the file.\n",
    "\n",
    "[file]: https://github.com/duckietown/dt-protocols/blob/daffy/src/dt_protocols/collision_protocol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the collision checker is a `MapDefinition`, which specifies the `environment` and `body`. \n",
    "The `environment` is all of the shapes that the robot can collide with, and the `body` is all of the shapes that\n",
    "make up the robot's body. Therefore, both `environment` and `body` are lists of `PlacedPrimitive`s. However, in\n",
    "the validation tests, the robot list will only contain one `PlacedPrimitive`.\n",
    "\n",
    "A `PlacedPrimitive` is a pair of a `FriendlyPose` and a `Primitive`, or a pose and a shape. Note that `theta_deg` in\n",
    "`FriendlyPose` starts at zero in the positive x-axis direction and ends at 359 degrees, moving in a counter-clockwise \n",
    "direction.\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlacedPrimitive:\n",
    "    pose: FriendlyPose\n",
    "    primitive: Primitive\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class FriendlyPose:\n",
    "    x: float\n",
    "    y: float\n",
    "    theta_deg: float\n",
    "```\n",
    "\n",
    "A `FriendlyPose` is a handy pose representation containing a (x,y) coordinate along with an angle. How friendly!\n",
    "\n",
    "A `Primitive` is either a `Rectangle` or a `Circle`. A circle's shape needs only be defined\n",
    "by a `radius`, while a Rectangle is defined by four values:\n",
    " - `xmax` is the distance from the pose point to its side in the positive x direction (if theta_deg in `FriendlyPose` is zero, this side is on the right of the pose point).\n",
    " - `xmin` is the same, but in the negative x direction\n",
    " - `ymax` is the distance from the center point to its side in the positive y direction (if theta_deg in `FriendlyPose` is zero, this side is on the top of the pose point).\n",
    " - `ymin` is the same, but in the negative y direction\n",
    " \n",
    "`xmax`, `xmin`, `ymax`, and `ymin` are all given with respect to the robot/obstacle's coordinate system, and not the world coordinate system. Therefore, the theta_deg value of the `FriendlyPose` affects the rotation of the Rectangle.\n",
    "\n",
    "```python\n",
    "\n",
    "@dataclass\n",
    "class Circle:\n",
    "    radius: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rectangle:\n",
    "    xmin: float\n",
    "    ymin: float\n",
    "    xmax: float\n",
    "    ymax: float\n",
    "\n",
    "Primitive = Union[Circle, Rectangle]\n",
    "```\n",
    "\n",
    "So, we represents shapes as the union of rototranslated `Rectangle`s and `Circle`s.\n",
    "\n",
    "The class `CollisionChecker` in `collision_checker.py` first receives a message `MapDefinition` to define the environment and robot shape. It also contains a default pose for the robot (0, 0). Then, it recieves a sequence of `CollisionCheckQuery`s. The query contains a new pose for the robot, which you will need to cross-reference against the `MapDefinition` to detect collisions. \n",
    "\n",
    "Therefore, the `CollisionChecker` must take the new pose from the `CollisionCheckQuery`, combine it with the default pose already contained the the robot's `PlacedPrimitive`s, and then see if it collides with any part of the environment. The result of this will go into a `CollisionCheckResult`. The `CollisionCheckResult` contains only a boolean: true means that it is in collision, false means that it is not in collision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template\n",
    "\n",
    "In [`collision_checker.py`][file] you will find the template for the collision checker.\n",
    "\n",
    "[file]: ./collision_checker.py\n",
    "\n",
    "## Visualization\n",
    "\n",
    "The challenge's output will be a series of images in a folder that is output at the end of the evaluation. The path will be something like:\n",
    "\n",
    "`/tmp/![username]/duckietown/dt-challenges-runner/local-evals/mooc-collision-check-vali/![date]/step1/tmp/![random]/`\n",
    "\n",
    "In the `images` folder you will see the queries with the ground truth,\n",
    "as the image shows.\n",
    "\n",
    "![query](media/env18.png)\n",
    "\n",
    "Colors:\n",
    "\n",
    "- $\\color{blue}{\\text{Blue}}$ is a pose in which the robot does not collide.\n",
    "- $\\color{red}{\\text{Red}}$ is a pose in which the robot collides.\n",
    "\n",
    "In the `results` folder you will see your results and the errors you made:\n",
    "\n",
    "![result](media/env18-result.png)\n",
    "\n",
    "The colors mean the following:\n",
    "\n",
    "- $\\color{blue}{\\text{Blue}}$ is a pose in which the robot does not collide and you guessed **RIGHT**.\n",
    "- $\\color{orange}{\\text{Orange}}$ is a pose in which the robot does not collide and you guessed **WRONG**.\n",
    "- $\\color{red}{\\text{Red}}$ is a pose in which the robot collides and you guessed **RIGHT**.\n",
    "- $\\color{pink}{\\text{Pink}}$ is a pose in which the robot collides and you guessed **WRONG**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for implementing the collision checker\n",
    "\n",
    "There are multiple ways to implement the collision checker. Here are some tips, but feel free to follow your intuition.\n",
    "\n",
    "### Use decomposition\n",
    "\n",
    "The first thing to note is that the problem can be *decomposed*.\n",
    "\n",
    "You are asked to see whether the robot collides with the environment at a certain pose.\n",
    "The robot is a list of `PlacedPrimitive`s and the environment is a list of `PlacedPrimitive`s. Remember, \n",
    "a `PlacedPrimitive` is the combination of a pose and a primitive, or in other terms, a location and\n",
    "a shape. In pseudocode:\n",
    "\n",
    "    robot =  rp1 ∪ rp2 ∪ rp3 ∪ ...\n",
    "    environment =  obj1 ∪ obj2 ∪ obj3 ∪ ...\n",
    "\n",
    "What you have to check is whether the intersection\n",
    "\n",
    "    robot ∩ environment\n",
    "\n",
    "is empty. By substituting terms we obtain:\n",
    "\n",
    "    (rp1 ∪ rp2 ∪ ...) ∩ (obj1 ∪ obj2 ∪ ...)\n",
    "\n",
    "Now, the intersection of unions is a union of intersection:\n",
    "\n",
    "    [rp1 ∩ (wc1 ∪ wc2 ∪ ...)]  ∪  [rp2 ∩ (wc1 ∪ wc2 ∪ ...)] ∪ ...\n",
    "\n",
    "The above shows that you have to check whether any primitive of the robot collides with environment.\n",
    "\n",
    "Further expanding the first term we obtain:\n",
    "\n",
    "    [rp1 ∩ (obj1 ∪ obj2 ∪ ...)] = (rp1 ∩ obj1) ∪ (rp2 ∩ obj2) ∪ ...\n",
    "\n",
    "This shows that in the end, you can reduce to problem to checking pairwise intersection of `PlacedPrimitives`. \n",
    "Therefore, using *decomposition*, we have simplified the problem of \"Does the robot collide with \n",
    "the environment?\" to asking \"Does this part of the robot collide with this environmental object?\". We ask\n",
    "this second question multiple times for each query. If the answer to this second question is ever yes, then \n",
    "we know that the robot collides with the environment.\n",
    "\n",
    "This tip has already been partially implemented in `collision_checker.py`.\n",
    "In other words...\n",
    "\n",
    "```\n",
    "for each environment_shape in env:\n",
    "    for each robot_part in robot:\n",
    "        if collides:\n",
    "            return True\n",
    "return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to the poses\n",
    "\n",
    "Both robot and environment are lists of `PlacedPrimitives`.\n",
    "\n",
    "That is, we should rewrite the robot expression as:\n",
    "\n",
    "    robot = RT(pose1, primitive1) ∪ RT(pose2, primitive1) ∪ ...\n",
    "\n",
    "where `RT()` rototranslates a primitive by a pose. Also note that for each query the robot changes pose. Let's call this pose `Q`. Note that we have:\n",
    "\n",
    "Note that we have\n",
    "\n",
    "    robot at pose Q = RT(Q * pose1, primitive1) ∪ RT(Q * pose2, primitive1) ∪ ... \n",
    "\n",
    "where `Q * pose` represent matrix multiplication.\n",
    "\n",
    "The above says that you can \"push inside\" the global pose.\n",
    "\n",
    "### In the end, what is the core complexity?\n",
    "\n",
    "Following the above tips, you should be able to get to the point where you are left with checking the collision of two rototranslated primitives.\n",
    "\n",
    "Now notice that there are 3 cases:\n",
    "\n",
    "- `Circle` vs `Circle`\n",
    "- `Rectangle` vs `Circle`\n",
    "- `Rectangle` vs `Rectangle`\n",
    "\n",
    "\n",
    "Note that without loss of generality you can get to the point where you have one primitive at the origin (You put one primitive in the coordinate frame of the other). How would you go about it?\n",
    "\n",
    "`Circle` vs `Circle` is easy: two circles intersects if the distance of the centers is less than the sum of the radii. (The validation tests don't actually ever use a circle shape on a robot, so this case may seem unncessary, but it's useful to leave it in for learning purposes).\n",
    "\n",
    "For the others, you have to think about it... Use your robotic mind to engineer a solution!\n",
    "\n",
    "### Speeding things up using lower/upper bound heuristics\n",
    "\n",
    "If you want to speed things up, consider the following method, which allows to introduce a fast heuristic phase using only circle-to-circle comparisons.\n",
    "\n",
    "For each rectangle `R`, you can find `C1`, the largest circle that is contained in the rectangle, and `C2`, the smallest circle that contains the rectangle. These are an upper bound and a lower bound to the shape.\n",
    "\n",
    "    C1 ⊆ R ⊆ C2\n",
    "\n",
    "Now notice that:\n",
    "\n",
    "- if `C1` collides with a shape, also `R` does.  (but if it doesn't you cannot conclude anything)\n",
    "- if `C2` does not collide with a shape, `R` does not as well. (but if it does, you cannot conclude anything)\n",
    "\n",
    "Using this logic, you can implement a method that first checks quickly whether the circle approximations give already enough information to conclude collision/no-collision. Only if the first test is inconclusive you go to the more expensive component.\n",
    "\n",
    "### Speeding things up using bitmaps heuristics\n",
    "\n",
    "Another approach is using bitmaps to convert the environment to an image, where a black pixel means \"occupied\", and a white pixel means \"free\". \n",
    "\n",
    "Then you can do the same with the robot shape and obtain another bitmap.\n",
    "\n",
    "Then you check whether the two bitmaps intersect\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- reduces the problem of collision to drawing of shapes;\n",
    "- cheaper if shapes are very complex.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- There are subtle issues regarding the approximations you are making. What exactly does a pixel represent? is it a point, or is it an area? is this an optimistic or pessimistic approximation? The semantics of painting is unclear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
